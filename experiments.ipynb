{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LRmcaaPUiSL"
      },
      "source": [
        "# Experiments\n",
        "\n",
        "Embedchain is an Open Source RAG Framework that makes it easy to create and deploy AI apps. At its core, Embedchain follows the design principle of being \"Conventional but Configurable\" to serve both software engineers and machine learning engineers.\n",
        "\n",
        "\n",
        "Here is a very simple demo about how it work!\n",
        "\n",
        "Check us out: https://github.com/embedchain/embedchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj2UXTmhUkQt"
      },
      "source": [
        "First of all we install the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vrgoWyaLUldK"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade embedchain\n",
        "# Python version = 3.9\n",
        "# python -m venv .venv\n",
        "# !pip install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnJH6GOzUqd2"
      },
      "source": [
        "Now we import the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nR66RE_qUngy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from embedchain import App\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UesCuX4OVYQj"
      },
      "source": [
        "We instantiate the embechain bot. Remember to change the API key with you OpenAI api key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from enum import Enum \n",
        "\n",
        "class ModelProvider(Enum):\n",
        "    OpenAI: str = \"OpenAI\"\n",
        "    Google: str = \"Google\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_model_config(model_provider: ModelProvider, api_key: str) -> dict:\n",
        "    \"\"\"\n",
        "    Creates a configuration dictionary for the EmbedChain application based on the model provider.\n",
        "\n",
        "    Args:\n",
        "        model_provider: The model provider to use (e.g., OpenAI, Google).\n",
        "        api_key: The model provider API key to use (e.g., OpenAI, Google).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the configuration for the EmbedChain application.\n",
        "    \"\"\"\n",
        "\n",
        "    base_config = {\n",
        "        \"vectordb\": {\n",
        "            \"provider\": \"chroma\",\n",
        "            \"config\": {\n",
        "                \"collection_name\": \"chat-pdf\",\n",
        "                \"allow_reset\": True,\n",
        "            },\n",
        "        },\n",
        "        \"chunker\": {\n",
        "            \"chunk_size\": 2000,\n",
        "            \"chunk_overlap\": 0,\n",
        "            \"length_function\": \"len\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    if model_provider == ModelProvider.OpenAI:\n",
        "        base_config[\"llm\"] = {\n",
        "            \"provider\": \"openai\",\n",
        "            \"config\": {\n",
        "                \"model\": \"gpt-3.5-turbo-1106\",\n",
        "                \"temperature\": 0.5,\n",
        "                \"max_tokens\": 1000,\n",
        "                \"top_p\": 1,\n",
        "                \"stream\": True,\n",
        "                \"api_key\": \"{api_key}\",  # Placeholder for API key\n",
        "            },\n",
        "        }\n",
        "        base_config[\"embedder\"] = {\n",
        "            \"provider\": \"openai\",\n",
        "            \"config\": {\"api_key\": \"{api_key}\"},\n",
        "        }\n",
        "\n",
        "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    else:\n",
        "        base_config[\"llm\"] = {\n",
        "            \"provider\": \"google\",\n",
        "            \"config\": {\n",
        "                \"model\": \"gemini-1.5-pro-latest\", # gemini-pro\n",
        "                \"temperature\": 0.1,\n",
        "                \"max_tokens\": 2048,\n",
        "                \"top_p\": 1,\n",
        "                \"stream\": True,\n",
        "                # \"api_key\": \"{api_key}\",  # Placeholder for API key\n",
        "            },\n",
        "        }\n",
        "        base_config[\"embedder\"] = {\n",
        "            \"provider\": \"google\",\n",
        "            \"config\": {\n",
        "                \"model\": \"models/text-embedding-004\", # embedding-001\n",
        "                \"task_type\": \"retrieval_document\",\n",
        "                \"title\": \"Embeddings for SatoshiMentor\",\n",
        "                # \"api_key\": \"{api_key}\",  # Placeholder for API key\n",
        "            },\n",
        "        }\n",
        "\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "    return base_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PibHR1WYVU0b"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
        "api_key = \"AIzaSyDZAc6cy1U1SxIxKSYB5bMK8VVSr96_-sc\"\n",
        "config = create_model_config(ModelProvider.Google, api_key)\n",
        "app = App.from_config(config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1tubXFPVcdk"
      },
      "source": [
        "Now, add different data sources using embedchain's `.add()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "zIWEUy26VZtf",
        "outputId": "636d792f-cc15-4ac1-abeb-6573164f86c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inserting batches in chromadb: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ef2349f9e65b65c1483dfb9a6827e811'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# app.add(\"https://en.wikipedia.org/wiki/Elon_Musk\")\n",
        "# app.add(\"https://www.forbes.com/profile/elon-musk\")\n",
        "\n",
        "app.add('./TrainingData/block.md')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnULYfjXVpe_"
      },
      "source": [
        "Your bot is ready now. Ask your bot any questions using `.query()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIaQdFpvVsWb",
        "outputId": "e2cfe1c2-1a79-4adb-c03e-42d71efd5292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```\n",
            "+--------------------+\n",
            "|---Magic-Number-----| *--4--bytes\n",
            "+--------------------+\n",
            "|-----Blocksize------| *--4--bytes\n",
            "+--------------------+\n",
            "|----Block-Header----| *--80--bytes\n",
            "+--------------------+\n",
            "|----Txn-counter-----| *--VarInt(1-9-bytes)\n",
            "+--------------------+\n",
            "|---Transactions-----| *---transaction--list\n",
            "+--------------------+\n",
            "\n",
            "```\n",
            "\n",
            "*  **Magic Number:** This serves as the network identifier. \n",
            "*  **Block Size:** This is the size of the block in bytes.\n",
            "*  **Block Header:** This is used to identify a particular block on a bitcoin network.\n",
            "*  **Transaction Counter:** This is the number of Bitcoin transactions included in a block. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(app.query(\"What is a block in Bitcoin with diagram?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/embedchain/embedchain\n",
        "# https://medium.com/@WamiqRaza/how-to-create-virtual-environment-jupyter-kernel-python-6836b50f4bf4\n",
        "# \n",
        "# https://ai.google.dev/gemini-api/docs/models/gemini\n",
        "# https://github.com/dzstudio/similar-text/tree/master\n",
        "# https://firebase.google.com/docs/functions/get-started?gen=2nd#python\n",
        "# https://medium.com/msackiit/what-is-text-similarity-and-how-to-implement-it-c74c8b641883\n",
        "# https://stackoverflow.com/questions/57882417/is-it-possible-to-use-google-bert-to-calculate-similarity-between-two-textual-do\n",
        "# "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
